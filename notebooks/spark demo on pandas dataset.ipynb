{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo:\n",
    "\n",
    "1. load data from mysql\n",
    "2. convert to spark format\n",
    "3. try spark sql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.extend(['..'])\n",
    "\n",
    "from src.db import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-28 10:38:36,911 - simulation - INFO - Reading mysql table o_machine_table\n",
      "2017-08-28 10:38:49,246 - simulation - INFO - Redis write table o_machine_table succeed!\n"
     ]
    }
   ],
   "source": [
    "table = load_from_mysql('o_machine_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table = table.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 155380 entries, 0 to 155379\n",
      "Data columns (total 8 columns):\n",
      "equipment_id       155380 non-null object\n",
      "parcel_id          155380 non-null object\n",
      "small_id           155380 non-null object\n",
      "parcel_type        155380 non-null object\n",
      "time_stamp         155380 non-null float64\n",
      "action             155380 non-null object\n",
      "real_time_stamp    155380 non-null datetime64[ns]\n",
      "run_time           155380 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(1), object(5)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sqlCtx = SQLContext(sc)\n",
    "spark_df = sqlCtx.createDataFrame(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark_df.createOrReplaceTempView(\"machine_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  155380|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlDF = spark.sql(\"SELECT count(*) FROM machine_table\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.57 ms, sys: 3.83 ms, total: 5.41 ms\n",
      "Wall time: 105 ms\n",
      "+------------+-------------------------+\n",
      "|equipment_id|count(DISTINCT parcel_id)|\n",
      "+------------+-------------------------+\n",
      "|       c3_16|                        9|\n",
      "|       c7_66|                        8|\n",
      "|      c14_24|                        3|\n",
      "|       c4_19|                        2|\n",
      "|      c13_18|                        1|\n",
      "|        c3_7|                       53|\n",
      "|       c9_79|                        2|\n",
      "|      c7_104|                        2|\n",
      "|      c10_85|                        4|\n",
      "|       c9_53|                        2|\n",
      "|       c7_71|                       27|\n",
      "|        m1_2|                       23|\n",
      "|       c7_41|                       28|\n",
      "|      c10_70|                        9|\n",
      "|       i11_1|                       32|\n",
      "|       j38_1|                        3|\n",
      "|       c1_20|                        9|\n",
      "|       c8_26|                        2|\n",
      "|        c8_1|                      219|\n",
      "|       c7_26|                        7|\n",
      "+------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 18.8 ms, sys: 7.33 ms, total: 26.1 ms\n",
      "Wall time: 5.57 s\n"
     ]
    }
   ],
   "source": [
    "%time sqlDF2 = spark.sql(\"SELECT equipment_id, count(distinct(parcel_id)) FROM machine_table group by equipment_id\")\n",
    "%time sqlDF2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (simpy_pip)",
   "language": "python",
   "name": "simpy_pip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
